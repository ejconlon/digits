% Preamble
% ---
\documentclass{article}

% Packages
% ---
\usepackage{amsmath} % Advanced math typesetting
\usepackage[utf8]{inputenc} % Unicode support (Umlauts etc.)
\usepackage[english]{babel}
\usepackage{hyperref} % Add a link to your document
\usepackage{graphicx} % Add pictures to your document
\usepackage{listings} % Source code formatting and highlighting
\usepackage{csquotes}
\usepackage{svg}
\usepackage[
backend=biber,
style=alphabetic,
sorting=ynt
]{biblatex}

\addbibresource{report.bib}
\setlength{\parskip}{1em}
\setsvg{svgpath = /Users/charolastra/school/digits/results/}

% Main document
% ---
\begin{document}
% Set up the maketitle command
\author{Eric Conlon}
\title{Classifying Street View House Numbers with Deep Learning}
\date{2016-11-9}

\maketitle{} % Generates title

\tableofcontents{} % Generates table of contents from sections

\section{Introduction}

Character recognition is a classic computer vision problem with many interesting variants. Even restricting ourselves to 10-digit classification still leaves much room for uncertainty and creativity. The Street View House Numbers dataset (SVHN) \cite{netzer2011reading} poses a such a classification problem that is generally considered to be tougher than the common MNIST dataset \cite{lecun1998mnist}.

In this report I explain some simple approaches to classification of both datasets with both conventional and deep learning methods. The conventional baseline here is a Support Vector Classifier using Histogram of Gradients features, and the deep learning challenger is a Convolutional Neural Network. These solutions may not rank among the state of the art, but it is my hope that the details of end-to-end architecture and practical engineering considerations will prove to be interesting.

\section{Datasets}

MNIST is a classic labeled dataset consisting of single handwritten digits (0-9) that have been extensively processed. Each digit is centered alone within a 28x28 grid, and all pixel intensities are set to 0 (background) and 1 (foreground). These images do not require common preprocessing techniques such as rescaling, contrast enhancement, or whitening to be immediately useful. There are around 60,000 training examples and 10,000 test examples.

SVHN is a labeled dataset that comes from images of house numbers collected by Google's Street View project. The digits have a wide variety of foreground and background colors, textures, noise, distractions, orientations, and scales. There are two formats provided: the first includes raw images with sets of bounding rectangles, and the second includes a more MNIST-like centered digits. The models here consume only the second format, but I will say more about this classifiers applicability to the first. Overall, this dataset contains almost 8 times more examples than MNIST.

\section{Design, Exploration, and Evaluation}

There are a few guiding principles to the implementation of this application:

\begin{itemize}
\item It must be possible train, test, explore, and evaluate independently
\item Model selection should be an automated part of the training process
\item Common metrics and visualizations should apply to any model and dataset
\end{itemize}

\begin{figure}[htbp]
  \centering
  \includesvg[height=\textheight,width=\columnwidth]{pipeline}
  \caption{Pipeline stages}
  \label{fig:pipeline}
\end{figure}

See Figure \ref{fig:pipeline} for a visualization of the pipeline.

- Preprocessing of images
- Train/Valid/Test split
- Parameter selection
- Standard metrics

\section{Conventional Solution}

- Conventional learning requires feature extraction before learning
- Like the paper, Use HOG + SVM
- Practical reasons prevent SVM from being trained on the large cropped dataset so compare mnist

\section{Deep Learning Solution}

- Use CNN
- No features extraction step
- Does require extensive tuning and parameter selection
- Voting improves performance

\section{Conclusion}

\printbibliography[heading=bibintoc,title={References}]

\end{document}